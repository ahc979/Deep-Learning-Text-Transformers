# Deep-Learning-Text-Transformers
Here I will show you part of my final master project where I had to qualify the different elements of a script using first neural networks like LSTM through Keras and Tensorflow and then Transformers with Pytorch and HuggingFace.

In this work, although it is not shown in the code, techniques such as Latent Dirich Allocation and n-grams were used, in addition to many other NLP and text mining techniques
